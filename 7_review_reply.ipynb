{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d75546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5d34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a045b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "\n",
    "    sentiment: Literal[\"positive\", \"negative\"] = Field(description='Sentiment of the review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c5f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4383a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = llm.with_structured_output(SentimentSchema)\n",
    "structured_model2 = llm.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989c1c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'What is the sentiment of the following review - The software too good'\n",
    "structured_model.invoke(prompt).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f950c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a400c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState):\n",
    "\n",
    "    prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = structured_model.invoke(prompt).sentiment\n",
    "\n",
    "    return {'sentiment': sentiment}\n",
    "\n",
    "def check_sentiment(state: ReviewState) -> Literal[\"positive_response\", \"run_diagnosis\"]:\n",
    "\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "    \n",
    "def positive_response(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Write a warm thank-you message in response to this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "Also, kindly ask the user to leave feedback on our website.\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "\"\"\"\n",
    "    response = structured_model2.invoke(prompt)\n",
    "\n",
    "    return {'diagnosis': response.model_dump()}\n",
    "\n",
    "def negative_response(state: ReviewState):\n",
    "\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7ad289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "\n",
    "graph.add_edge('positive_response', END)\n",
    "\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34deb0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.',\n",
       " 'sentiment': 'negative',\n",
       " 'diagnosis': {'issue_type': 'Bug', 'tone': 'angry', 'urgency': 'high'},\n",
       " 'response': \"Subject: Re: Urgent: Bug Issue - High Priority\\n\\nDear [User's Name],\\n\\nI'm so sorry to hear that you're experiencing a frustrating issue with our system. I can imagine how infuriating it must be when something isn't working as expected, especially when you're under a tight deadline.\\n\\nPlease know that I'm here to help and will do my best to resolve this issue for you as quickly as possible. I've taken note of the details you provided, and I'm going to escalate this to our development team to investigate further.\\n\\nIn the meantime, I'd like to offer some temporary workarounds to help you get back on track. Have you tried [list any possible temporary solutions or workarounds]? If not, I can provide more information on how to implement these.\\n\\nTo ensure that we resolve this issue efficiently, I'd like to ask a few more questions:\\n\\n1. Can you please provide more details about the error message you're seeing?\\n2. What steps were you taking when the issue occurred?\\n3. Are there any specific features or functionalities that are not working as expected?\\n\\nYour prompt response will help me to better understand the issue and provide a more effective solution.\\n\\nThank you for your patience and cooperation. I'll keep you updated on the progress and will notify you as soon as the issue is resolved.\\n\\nBest regards,\\n\\n[Your Name]\\nSupport Assistant\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intial_state={\n",
    "    'review': \"I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\"\n",
    "}\n",
    "workflow.invoke(intial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
